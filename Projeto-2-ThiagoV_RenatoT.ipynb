{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento \n",
    "\n",
    "### Renato Tajima e Thiago Verardo\n",
    "\n",
    "\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando os tweets do mouse G403\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando os tweets a serem analisados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse item nós importamos uma tabela de tweets e os classificamos, manualmente, um a um se eles são relevantes ou não para o desenvolvimento do produto, ou seja, se eles constituem uma crítica positiva ou negativa, com o objetivo de eles servirem como uma forma de modelo para o nosso código no final.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets_treinamento.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d3109b61615a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTreinamento\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets_treinamento.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mTeste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tweets_teste.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mTreinamento\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, skiprows, skip_footer, index_col, names, usecols, parse_dates, date_parser, na_values, thousands, convert_float, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     return io._parse_excel(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets_treinamento.xlsx'"
     ]
    }
   ],
   "source": [
    "Treinamento = pd.read_excel('tweets_treinamento.xlsx')\n",
    "Teste = pd.read_excel('Tweets_teste.xlsx')\n",
    "\n",
    "\n",
    "Treinamento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpando os tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após importamos a tabelas, temos que retirar alguns caracteres que podem atrapalhar o classificador, como pontos, espaços, virgulas, tab, três pontos, enters, #, http, rt e @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "pontuacao = string.punctuation\n",
    "\n",
    "#Primeira Limpada\n",
    "\n",
    "#lista de itens indesejáveis (pontos, espaços, virgulas, tab, três pontos e enters)\n",
    "pont = [\",\" ,\"\\n\", \"\\t\", \".\", \"…\"]\n",
    "\n",
    "tweet = Treinamento[\"Treinamento\"]\n",
    "\n",
    "tweets_limpos = []\n",
    "\n",
    "for e in tweet:\n",
    "    a = \"\"\n",
    "    for i in e:\n",
    "        if i in UNICODE_EMOJI:\n",
    "            a = a+\" \"+i+\" \"\n",
    "        elif i in pont:\n",
    "            a += \" \"\n",
    "        elif i not in pontuacao:\n",
    "            a+= i\n",
    "    tweets_limpos.append(a)\n",
    "    \n",
    "g403_limpo = pd.DataFrame()\n",
    "g403_limpo[\"tweets\"] = tweets_limpos\n",
    "g403_limpo[\"Relevância\"] = Treinamento[\"Class\"]\n",
    "\n",
    "g403_limpo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segunda Limpada\n",
    "#Retirando os #, http, rt e @.\n",
    "\n",
    "tweet_limpo = []\n",
    "y = \" \"\n",
    "for tweet in g403_limpo[\"tweets\"]:\n",
    "    limpo = []\n",
    "    split = tweet.split(\" \")\n",
    "    for e in split:\n",
    "        if e in UNICODE_EMOJI:\n",
    "            limpo.append(e)\n",
    "        elif len(e)>2 and e[0] != \"@\" and e[0] != \"#\" and e[0] != \"rt\" and e[:4] != \"http\":\n",
    "            limpo.append(e)\n",
    "    tweet_limpo.append(y.join(limpo))\n",
    "    \n",
    "g403_pronto = pd.DataFrame()\n",
    "g403_pronto[\"tweets\"] = tweet_limpo\n",
    "g403_pronto[\"Relevância\"] = Treinamento[\"Class\"]\n",
    "\n",
    "g403_pronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lógica de classificação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desesnvolver o nosso classificador nós colocamos as palavras dos tweets em uma lista com o método split e depois a comparamos com a nossa tabela tweets, para analisarmos quais as palavras que aparecem mais nos tweets relevantes e irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = []\n",
    "\n",
    "for e in g403_pronto[\"tweets\"]:\n",
    "    split = e.split(\" \")\n",
    "    for i in split:\n",
    "        if i not in palavras:\n",
    "            palavras.append(i)\n",
    "palavras_relevantes = 0\n",
    "palavras_irrelevantes = 0\n",
    "for e in range(len(g403_pronto[\"tweets\"])):\n",
    "    split = g403_pronto[\"tweets\"][e].split(\" \")\n",
    "    if g403_pronto[\"Relevância\"][e] == 1:\n",
    "        for i in split:\n",
    "            palavras_relevantes += 1\n",
    "    else:\n",
    "        for i in split:\n",
    "            palavras_irrelevantes += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a probabilidade\n",
    "\n",
    "Com as palavras separadas e analisadas, podemos calcular P( palavra | relevante ) e P( palavra | não relevante ) e P( relevante ) e P( não relevante ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante = {}\n",
    "irrelevante = {}\n",
    "\n",
    "for e in palavras:\n",
    "    relevante[e] = 1\n",
    "    irrelevante[e] = 1\n",
    "\n",
    "for i in range(len(g403_pronto[\"tweets\"])):\n",
    "    split = g403_pronto[\"tweets\"][i].split(' ')\n",
    "    if g403_pronto['Relevância'][i] == 1:\n",
    "        for a in split:\n",
    "            relevante[a] += 1\n",
    "    else:\n",
    "        for b in split:\n",
    "            irrelevante[b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rel = {}\n",
    "prob_irrel = {}\n",
    "\n",
    "for e in palavras:\n",
    "    prob_rel[e] = relevante[e] / (palavras_relevantes + len(palavras))\n",
    "    prob_irrel[e] = irrelevante[e] / (palavras_irrelevantes + len(palavras))\n",
    "    \n",
    "s_rel = 0\n",
    "s_irrel = 0\n",
    "for i in g403_pronto[\"Relevância\"]:\n",
    "    if i == 0:\n",
    "        s_irrel +=1\n",
    "    else:\n",
    "        s_rel +=1\n",
    "        \n",
    "prob_relevante = s_rel / len(g403_pronto[\"Relevância\"])\n",
    "prob_irrelevante = s_irrel / len(g403_pronto[\"Relevância\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso devemos refazer o processo com um dataframe novo, nesse caso foi o \"Teste\" (previamente criado). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpá-lo, como o outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "pontuacao = string.punctuation\n",
    "\n",
    "pont = [\",\" ,\"\\n\", \"\\t\", \".\"]\n",
    "\n",
    "tweet = Teste[\"Teste\"]\n",
    "\n",
    "tweets_limpos = []\n",
    "\n",
    "for e in tweet:\n",
    "    a = \"\"\n",
    "    for i in e:\n",
    "        if i in UNICODE_EMOJI:\n",
    "            a = a+\" \"+i+\" \"\n",
    "        elif i in pont:\n",
    "            a+= \" \"\n",
    "        elif i not in pontuacao:\n",
    "            a+= i\n",
    "    tweets_limpos.append(a)\n",
    "    \n",
    "teste_limpo = pd.DataFrame()\n",
    "teste_limpo[\"tweets\"] = tweets_limpos\n",
    "teste_limpo[\"Relevância\"] = Teste[\"Class\"]\n",
    "\n",
    "tweet_limpo = []\n",
    "y = \" \"\n",
    "for tweet in teste_limpo[\"tweets\"]:\n",
    "    limpo = []\n",
    "    split = tweet.split(\" \")\n",
    "    for e in split:\n",
    "        if e in UNICODE_EMOJI:\n",
    "            limpo.append(e)\n",
    "        elif len(e)>2 and e[0] != \"@\" and e[0] != \"#\" and e[0] != \"rt\" and e[:4] != \"http\":\n",
    "            limpo.append(e)\n",
    "    tweet_limpo.append(y.join(limpo))\n",
    "    \n",
    "teste_pronto = pd.DataFrame()\n",
    "teste_pronto[\"tweets\"] = tweet_limpo\n",
    "teste_pronto[\"Class\"] = Teste[\"Class\"]\n",
    "\n",
    "teste_pronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o dataframe limpo, podemos fazer a previsão se um tweet é relevante, ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = []\n",
    "\n",
    "for e in teste_pronto[\"tweets\"]:\n",
    "    prob_relev = 1\n",
    "    prob_irrelev = 1\n",
    "    palavras = e.split(\" \")\n",
    "    \n",
    "    for i in palavras:\n",
    "        if i in prob_rel:\n",
    "            prob_relev *= prob_rel[i]\n",
    "        else:\n",
    "            prob_relev *= (1/(s_rel + len(palavras)))\n",
    "        \n",
    "    for i in palavras:\n",
    "        if i in prob_irrel:\n",
    "            prob_irrelev *= prob_irrel[i]\n",
    "        else:\n",
    "            prob_irrelev *= (1/(s_irrel + len(palavras)))\n",
    "    relevantes = prob_relev * prob_relevante\n",
    "    irrelevantes = prob_irrelev * prob_irrelevante\n",
    "    \n",
    "    if relevantes > irrelevantes:\n",
    "        previsao.append(1)\n",
    "    else:\n",
    "        previsao.append(0)\n",
    "        \n",
    "teste_pronto[\"Previsão\"] = previsao\n",
    "\n",
    "teste_pronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso feito, podemos calcular a Porcentagem de positivos falsos, Porcentagem de positivos verdadeiros, Porcentagem de negativos verdadeiros e Porcentagem de negativos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crelevantes = 0\n",
    "cirrelevantes = 0\n",
    "\n",
    "for i in range(len(teste_pronto['Class'])):\n",
    "    if teste_pronto['Class'][i] == 1:\n",
    "        crelevantes += 1\n",
    "    else:\n",
    "        cirrelevantes += 1\n",
    "\n",
    "prcr = 0\n",
    "pircr = 0\n",
    "prcir = 0\n",
    "pircir = 0\n",
    "\n",
    "for i in range(len(teste_pronto['Previsão'])):\n",
    "    if teste_pronto['Previsão'][i] == 1 and teste_pronto['Class'][i] == 1:\n",
    "        prcr += 1\n",
    "    elif teste_pronto['Previsão'][i] == 0 and teste_pronto['Class'][i] == 1:\n",
    "        pircr += 1\n",
    "    elif teste_pronto['Previsão'][i] == 1 and teste_pronto['Class'][i] == 0:\n",
    "        prcir += 1\n",
    "    else:\n",
    "        pircir += 1\n",
    "        \n",
    "P_pos_falso = prcir / cirrelevantes\n",
    "P_pos_verdadeiro = prcr / crelevantes\n",
    "P_neg_verdadeiro = pircir / cirrelevantes\n",
    "P_neg_falso = pircr / crelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de positivos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pos_falso * 100\n",
    "print(P_pos_falso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de positivos verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pos_verdadeiro * 100\n",
    "print(P_pos_verdadeiro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de negativos verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_neg_verdadeiro * 100\n",
    "print(P_neg_verdadeiro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de negativos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_neg_falso * 100\n",
    "print(P_neg_falso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, por fim, calcular a porcentagem de acertos do classificador de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos = 0\n",
    "\n",
    "for i in range(len(teste_pronto['Previsão'])):\n",
    "    if teste_pronto['Previsão'][i] == teste_pronto['Class'][i]:\n",
    "        acertos += 1\n",
    "        \n",
    "Precisao = acertos / len(teste_pronto)\n",
    "\n",
    "print('O classificador acerta a relevância de um tweet em {0:.2f}% dos casos.'.format(Precisao * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse projeto nós buscamos criar um classificador de palavras, confiável, para se analisar algum produto específico que está sendo discutido no twitter, no nosso caso foi o mouse g403.\n",
    "\n",
    "Para começar a fazer esse projeto nós importamos uma tabela de tweets que falava sobre o produto desejado. Após importá-la, conseguimos desenvolver uma lógica para conseguir classificar cada tweet dentro dela entre relevante ou irrelevante, ou seja, se o tweet faz uma crítica ao produto ou não.\n",
    "\n",
    "Ao desenvolver o nosso classificador, nós consideramos todas as palavras relevantes dos tweets e os emojis presentes nele, para que assim nós possamos classificar as palavras em positivas verdadeiras (uma palavra que foi identificada como relevante e realmente é), positivas falsas (uma palavra que foi identificada como relevante e na verdade não é), negativo verdadeiro (uma palavra que foi identificada como irrelevante e realmente é) e negativo falso (uma palavra que foi identificada como irrelevante e é relevante). \n",
    "\n",
    "Após as suas classificações nós obtivemos que o nosso modelo possui um alto percentual de acertos entre os item relevantes, sendo ele de 88.50%, e o mais incrível ainda é que o nosso modelo consegue prever 100% dos tweets positivos e verdadeiros. Mostrando que o nosso modelo pode vir a ser muito útil para a avaliação de algum produto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão qualitativa sobre as medidas obtidas.\n",
    "\n",
    "O nosso modelo de classificador, após analisar todos os tweets, conseguiu apresenta uma incrível precisão de 88,5% de detectção de tweets verdadeiros e relevantes, sendo que ele detecta 100% dos tweets positivos verdadeiros e, logicamente, 0% dos tweets verdadeiros negativos. Mostrando que nosso modelo é muito eficaz dentro de suas limitações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mensagens com dupla negação e sarcasmo\n",
    "\n",
    "As mensagens com dupla negação e sacarsmos são complexas para se lidar com um classificador didático, uma vez que envolvem sentimentos e interpretações humanas. O nosso classificador não é capaz de detectar esses sentimentos, uma vez que ele só classifica as palavras e faz suas possibilidades, e não verifica o signifado por trás delas. A análise é feita somente com a palavra, não com o conjunto ou combinação delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plano de Expansão\n",
    "\n",
    "Como dito anteriormente, nosso classificador apresentou um percentual muito elevado na detecção de tweets realmentes relevantes e o mais incrível ainda é que ele consegue prever 100% dos tweets classificados como positivos verdadeiros, mostrando que ele pode ser confiável e útil para qualquer empresa que venha a usá-lo no futuro.\n",
    "\n",
    "Porém, como todo modelo, ele consegue ficar cada vez melhor e com ajuda de investimentos externos isso pode ser possível, uma vez que o dinheiro for aplicado, será possível criar um banco de dados maior, deixando ele muito mais preciso e uma melhoraria no filtro das palavras, com o objetivo de classificar o maior número de palavras que são classificadas como relevantes ou como irrelevantes, fazendo com que o classificador fique mais apurado. Além de uma aumentada no número de palavras \"irrelevantes\", que não agregam à relevância da resposta, para se ter um dataframe mais limpo e capaz de relacionar melhor as palavras.\n",
    "\n",
    "Vê se que o potencial desse classificador é muito grande para empresas que recebem \"feedback\" e comentários de muitas pessoas todos os dias, pois o tempo de identificar comentários relevantes seria poupado, além de dar a opção delas darem o \"feedback\" ao consumidor/cliente mais rapidamente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
