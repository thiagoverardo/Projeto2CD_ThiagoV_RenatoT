{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento \n",
    "\n",
    "### Renato Tajima e Thiago Verardo\n",
    "\n",
    "\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando os tweets do mouse G403\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando os tweets a serem analisados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse item nós importamos uma tabela de tweets e os classificamos, manualmente, um a um se eles são relevantes ou não para o desenvolvimento do produto, ou seja, se eles constituem uma crítica positiva ou negativa, com o objetivo de eles servirem como uma forma de modelo para o nosso código no final.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best gaming mouse-logitech g903,g403,g703 and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @tsmviss: new giveaway!\\ngiving away 3 sets...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @gdw444: 2018-2019 mpp students @policy_sch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @imnategibson: g403 paracorded. https://t.c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @tsmviss: new giveaway!\\ngiving away 3 sets...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Class\n",
       "0  best gaming mouse-logitech g903,g403,g703 and ...      1\n",
       "1  rt @tsmviss: new giveaway!\\ngiving away 3 sets...      0\n",
       "2  rt @gdw444: 2018-2019 mpp students @policy_sch...      0\n",
       "3  rt @imnategibson: g403 paracorded. https://t.c...      0\n",
       "4  rt @tsmviss: new giveaway!\\ngiving away 3 sets...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Treinamento = pd.read_excel('tweets_treinamento.xlsx')\n",
    "Teste = pd.read_excel('Tweets_teste.xlsx')\n",
    "\n",
    "\n",
    "Treinamento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpando os tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após importamos a tabelas, temos que retirar alguns caracteres que podem atrapalhar o classificador, como pontos, espaços, virgulas, tab, três pontos, enters, #, http, rt e @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best gaming mouselogitech g903 g403 g703 and g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt tsmviss new giveaway giving away 3 sets of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt gdw444 20182019 mpp students policyschool u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt imnategibson g403 paracorded  httpst coq0op...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt tsmviss new giveaway giving away 3 sets of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Relevância\n",
       "0  best gaming mouselogitech g903 g403 g703 and g...           1\n",
       "1  rt tsmviss new giveaway giving away 3 sets of ...           0\n",
       "2  rt gdw444 20182019 mpp students policyschool u...           0\n",
       "3  rt imnategibson g403 paracorded  httpst coq0op...           0\n",
       "4  rt tsmviss new giveaway giving away 3 sets of ...           0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "pontuacao = string.punctuation\n",
    "\n",
    "#Primeira Limpada\n",
    "\n",
    "#lista de itens indesejáveis (pontos, espaços, virgulas, tab, três pontos e enters)\n",
    "pont = [\",\" ,\"\\n\", \"\\t\", \".\", \"…\"]\n",
    "\n",
    "tweet = Treinamento[\"Treinamento\"]\n",
    "\n",
    "tweets_limpos = []\n",
    "\n",
    "for e in tweet:\n",
    "    a = \"\"\n",
    "    for i in e:\n",
    "        if i in UNICODE_EMOJI:\n",
    "            a = a+\" \"+i+\" \"\n",
    "        elif i in pont:\n",
    "            a += \" \"\n",
    "        elif i not in pontuacao:\n",
    "            a+= i\n",
    "    tweets_limpos.append(a)\n",
    "    \n",
    "g403_limpo = pd.DataFrame()\n",
    "g403_limpo[\"tweets\"] = tweets_limpos\n",
    "g403_limpo[\"Relevância\"] = Treinamento[\"Class\"]\n",
    "\n",
    "g403_limpo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best gaming mouselogitech g903 g403 g703 and g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gdw444 20182019 mpp students policyschool ucal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imnategibson g403 paracorded coq0opm8kh4v</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Relevância\n",
       "0  best gaming mouselogitech g903 g403 g703 and g...           1\n",
       "1  tsmviss new giveaway giving away sets peripher...           0\n",
       "2  gdw444 20182019 mpp students policyschool ucal...           0\n",
       "3          imnategibson g403 paracorded coq0opm8kh4v           0\n",
       "4  tsmviss new giveaway giving away sets peripher...           0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Segunda Limpada\n",
    "#Retirando os #, http, rt e @.\n",
    "\n",
    "tweet_limpo = []\n",
    "y = \" \"\n",
    "for tweet in g403_limpo[\"tweets\"]:\n",
    "    limpo = []\n",
    "    split = tweet.split(\" \")\n",
    "    for e in split:\n",
    "        if e in UNICODE_EMOJI:\n",
    "            limpo.append(e)\n",
    "        elif len(e)>2 and e[0] != \"@\" and e[0] != \"#\" and e[0] != \"rt\" and e[:4] != \"http\":\n",
    "            limpo.append(e)\n",
    "    tweet_limpo.append(y.join(limpo))\n",
    "    \n",
    "g403_pronto = pd.DataFrame()\n",
    "g403_pronto[\"tweets\"] = tweet_limpo\n",
    "g403_pronto[\"Relevância\"] = Treinamento[\"Class\"]\n",
    "\n",
    "g403_pronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lógica de classificação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desesnvolver o nosso classificador nós colocamos as palavras dos tweets em uma lista com o método split e depois a comparamos com a nossa tabela tweets, para analisarmos quais as palavras que aparecem mais nos tweets relevantes e irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = []\n",
    "\n",
    "for e in g403_pronto[\"tweets\"]:\n",
    "    split = e.split(\" \")\n",
    "    for i in split:\n",
    "        if i not in palavras:\n",
    "            palavras.append(i)\n",
    "palavras_relevantes = 0\n",
    "palavras_irrelevantes = 0\n",
    "for e in range(len(g403_pronto[\"tweets\"])):\n",
    "    split = g403_pronto[\"tweets\"][e].split(\" \")\n",
    "    if g403_pronto[\"Relevância\"][e] == 1:\n",
    "        for i in split:\n",
    "            palavras_relevantes += 1\n",
    "    else:\n",
    "        for i in split:\n",
    "            palavras_irrelevantes += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a probabilidade\n",
    "\n",
    "Com as palavras separadas e analisadas, podemos calcular P( palavra | relevante ) e P( palavra | não relevante ) e P( relevante ) e P( não relevante ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante = {}\n",
    "irrelevante = {}\n",
    "\n",
    "for e in palavras:\n",
    "    relevante[e] = 1\n",
    "    irrelevante[e] = 1\n",
    "\n",
    "for i in range(len(g403_pronto[\"tweets\"])):\n",
    "    split = g403_pronto[\"tweets\"][i].split(' ')\n",
    "    if g403_pronto['Relevância'][i] == 1:\n",
    "        for a in split:\n",
    "            relevante[a] += 1\n",
    "    else:\n",
    "        for b in split:\n",
    "            irrelevante[b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rel = {}\n",
    "prob_irrel = {}\n",
    "\n",
    "for e in palavras:\n",
    "    prob_rel[e] = relevante[e] / (palavras_relevantes + len(palavras))\n",
    "    prob_irrel[e] = irrelevante[e] / (palavras_irrelevantes + len(palavras))\n",
    "    \n",
    "s_rel = 0\n",
    "s_irrel = 0\n",
    "for i in g403_pronto[\"Relevância\"]:\n",
    "    if i == 0:\n",
    "        s_irrel +=1\n",
    "    else:\n",
    "        s_rel +=1\n",
    "        \n",
    "prob_relevante = s_rel / len(g403_pronto[\"Relevância\"])\n",
    "prob_irrelevante = s_irrel / len(g403_pronto[\"Relevância\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso devemos refazer o processo com um dataframe novo, nesse caso foi o \"Teste\" (previamente criado). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking forward to having @tomclarkgpa in #yyc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @tsmviss: new giveaway!\\ngiving away 3 sets...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @tsmviss: new giveaway!\\ngiving away 3 sets...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @tsmviss: new giveaway!\\ngiving away 3 sets...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @tsmviss: new giveaway!\\ngiving away 3 sets...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Class\n",
       "0  looking forward to having @tomclarkgpa in #yyc...      0\n",
       "1  rt @tsmviss: new giveaway!\\ngiving away 3 sets...      0\n",
       "2  rt @tsmviss: new giveaway!\\ngiving away 3 sets...      0\n",
       "3  rt @tsmviss: new giveaway!\\ngiving away 3 sets...      0\n",
       "4  rt @tsmviss: new giveaway!\\ngiving away 3 sets...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpá-lo, como o outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking forward having tomclarkgpa yyc lead th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Class\n",
       "0  looking forward having tomclarkgpa yyc lead th...      0\n",
       "1  tsmviss new giveaway giving away sets peripher...      0\n",
       "2  tsmviss new giveaway giving away sets peripher...      0\n",
       "3  tsmviss new giveaway giving away sets peripher...      0\n",
       "4  tsmviss new giveaway giving away sets peripher...      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "pontuacao = string.punctuation\n",
    "\n",
    "pont = [\",\" ,\"\\n\", \"\\t\", \".\"]\n",
    "\n",
    "tweet = Teste[\"Teste\"]\n",
    "\n",
    "tweets_limpos = []\n",
    "\n",
    "for e in tweet:\n",
    "    a = \"\"\n",
    "    for i in e:\n",
    "        if i in UNICODE_EMOJI:\n",
    "            a = a+\" \"+i+\" \"\n",
    "        elif i in pont:\n",
    "            a+= \" \"\n",
    "        elif i not in pontuacao:\n",
    "            a+= i\n",
    "    tweets_limpos.append(a)\n",
    "    \n",
    "teste_limpo = pd.DataFrame()\n",
    "teste_limpo[\"tweets\"] = tweets_limpos\n",
    "teste_limpo[\"Relevância\"] = Teste[\"Class\"]\n",
    "\n",
    "tweet_limpo = []\n",
    "y = \" \"\n",
    "for tweet in teste_limpo[\"tweets\"]:\n",
    "    limpo = []\n",
    "    split = tweet.split(\" \")\n",
    "    for e in split:\n",
    "        if e in UNICODE_EMOJI:\n",
    "            limpo.append(e)\n",
    "        elif len(e)>2 and e[0] != \"@\" and e[0] != \"#\" and e[0] != \"rt\" and e[:4] != \"http\":\n",
    "            limpo.append(e)\n",
    "    tweet_limpo.append(y.join(limpo))\n",
    "    \n",
    "teste_pronto = pd.DataFrame()\n",
    "teste_pronto[\"tweets\"] = tweet_limpo\n",
    "teste_pronto[\"Class\"] = Teste[\"Class\"]\n",
    "\n",
    "teste_pronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o dataframe limpo, podemos fazer a previsão se um tweet é relevante, ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Class</th>\n",
       "      <th>Previsão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking forward having tomclarkgpa yyc lead th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsmviss new giveaway giving away sets peripher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Class  Previsão\n",
       "0  looking forward having tomclarkgpa yyc lead th...      0         1\n",
       "1  tsmviss new giveaway giving away sets peripher...      0         0\n",
       "2  tsmviss new giveaway giving away sets peripher...      0         0\n",
       "3  tsmviss new giveaway giving away sets peripher...      0         0\n",
       "4  tsmviss new giveaway giving away sets peripher...      0         0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = []\n",
    "\n",
    "for e in teste_pronto[\"tweets\"]:\n",
    "    prob_relev = 1\n",
    "    prob_irrelev = 1\n",
    "    palavras = e.split(\" \")\n",
    "    \n",
    "    for i in palavras:\n",
    "        if i in prob_rel:\n",
    "            prob_relev *= prob_rel[i]\n",
    "        else:\n",
    "            prob_relev *= (1/(s_rel + len(palavras)))\n",
    "        \n",
    "    for i in palavras:\n",
    "        if i in prob_irrel:\n",
    "            prob_irrelev *= prob_irrel[i]\n",
    "        else:\n",
    "            prob_irrelev *= (1/(s_irrel + len(palavras)))\n",
    "    relevantes = prob_relev * prob_relevante\n",
    "    irrelevantes = prob_irrelev * prob_irrelevante\n",
    "    \n",
    "    if relevantes > irrelevantes:\n",
    "        previsao.append(1)\n",
    "    else:\n",
    "        previsao.append(0)\n",
    "        \n",
    "teste_pronto[\"Previsão\"] = previsao\n",
    "\n",
    "teste_pronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso feito, podemos calcular a Porcentagem de positivos falsos, Porcentagem de positivos verdadeiros, Porcentagem de negativos verdadeiros e Porcentagem de negativos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "crelevantes = 0\n",
    "cirrelevantes = 0\n",
    "\n",
    "for i in range(len(teste_pronto['Class'])):\n",
    "    if teste_pronto['Class'][i] == 1:\n",
    "        crelevantes += 1\n",
    "    else:\n",
    "        cirrelevantes += 1\n",
    "\n",
    "prcr = 0\n",
    "pircr = 0\n",
    "prcir = 0\n",
    "pircir = 0\n",
    "\n",
    "for i in range(len(teste_pronto['Previsão'])):\n",
    "    if teste_pronto['Previsão'][i] == 1 and teste_pronto['Class'][i] == 1:\n",
    "        prcr += 1\n",
    "    elif teste_pronto['Previsão'][i] == 0 and teste_pronto['Class'][i] == 1:\n",
    "        pircr += 1\n",
    "    elif teste_pronto['Previsão'][i] == 1 and teste_pronto['Class'][i] == 0:\n",
    "        prcir += 1\n",
    "    else:\n",
    "        pircir += 1\n",
    "        \n",
    "P_pos_falso = prcir / cirrelevantes\n",
    "P_pos_verdadeiro = prcr / crelevantes\n",
    "P_neg_verdadeiro = pircir / cirrelevantes\n",
    "P_neg_falso = pircr / crelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de positivos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12432432432432433\n"
     ]
    }
   ],
   "source": [
    "P_pos_falso * 100\n",
    "print(P_pos_falso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de positivos verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "P_pos_verdadeiro * 100\n",
    "print(P_pos_verdadeiro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de negativos verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8756756756756757\n"
     ]
    }
   ],
   "source": [
    "P_neg_verdadeiro * 100\n",
    "print(P_neg_verdadeiro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de negativos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "P_neg_falso * 100\n",
    "print(P_neg_falso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, por fim, calcular a porcentagem de acertos do classificador de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O classificador acerta a relevância de um tweet em 88.50% dos casos.\n"
     ]
    }
   ],
   "source": [
    "acertos = 0\n",
    "\n",
    "for i in range(len(teste_pronto['Previsão'])):\n",
    "    if teste_pronto['Previsão'][i] == teste_pronto['Class'][i]:\n",
    "        acertos += 1\n",
    "        \n",
    "Precisao = acertos / len(teste_pronto)\n",
    "\n",
    "print('O classificador acerta a relevância de um tweet em {0:.2f}% dos casos.'.format(Precisao * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse projeto nós buscamos criar um classificador de palavras, confiável, para se analisar algum produto específico que está sendo discutido no twitter, no nosso caso foi o mouse g403.\n",
    "\n",
    "Para começar a fazer esse projeto nós importamos uma tabela de tweets que falava sobre o produto desejado. Após importá-la, conseguimos desenvolver uma lógica para conseguir classificar cada tweet dentro dela entre relevante ou irrelevante, ou seja, se o tweet faz uma crítica ao produto ou não.\n",
    "\n",
    "Ao desenvolver o nosso classificador, nós consideramos todas as palavras relevantes dos tweets e os emojis presentes nele, para que assim nós possamos classificar as palavras em positivas verdadeiras (uma palavra que foi identificada como relevante e realmente é), positivas falsas (uma palavra que foi identificada como relevante e na verdade não é), negativo verdadeiro (uma palavra que foi identificada como irrelevante e realmente é) e negativo falso (uma palavra que foi identificada como irrelevante e é relevante). \n",
    "\n",
    "Após as suas classificações nós obtivemos que o nosso modelo possui um alto percentual de acertos entre os item relevantes, sendo ele de 88.50%, e o mais incrível ainda é que o nosso modelo consegue prever 100% dos tweets positivos e verdadeiros. Mostrando que o nosso modelo pode vir a ser muito útil para a avaliação de algum produto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão qualitativa sobre as medidas obtidas.\n",
    "\n",
    "O nosso modelo de classificador, após analisar todos os tweets, conseguiu apresenta uma incrível precisão de 88,5% de detectção de tweets verdadeiros e relevantes, sendo que ele detecta 100% dos tweets positivos verdadeiros e, logicamente, 0% dos tweets verdadeiros negativos. Mostrando que nosso modelo é muito eficaz dentro de suas limitações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mensagens com dupla negação e sarcasmo\n",
    "\n",
    "As mensagens com dupla negação e sacarsmos são complexas para se lidar com um classificador didático, uma vez que envolvem sentimentos e interpretações humanas. O nosso classificador não é capaz de detectar esses sentimentos, uma vez que ele só classifica as palavras e faz suas possibilidades, e não verifica o signifado por trás delas. A análise é feita somente com a palavra, não com o conjunto ou combinação delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plano de Expansão\n",
    "\n",
    "Como dito anteriormente, nosso classificador apresentou um percentual muito elevado na detecção de tweets realmentes relevantes e o mais incrível ainda é que ele consegue prever 100% dos tweets classificados como positivos verdadeiros, mostrando que ele pode ser confiável e útil para qualquer empresa que venha a usá-lo no futuro.\n",
    "\n",
    "Porém, como todo modelo, ele consegue ficar cada vez melhor e com ajuda de investimentos externos isso pode ser possível, uma vez que o dinheiro for aplicado, será possível criar um banco de dados maior, deixando ele muito mais preciso e uma melhoraria no filtro das palavras, com o objetivo de classificar o maior número de palavras que são classificadas como relevantes ou como irrelevantes, fazendo com que o classificador fique mais apurado. Além de uma aumentada no número de palavras \"irrelevantes\", que não agregam à relevância da resposta, para se ter um dataframe mais limpo e capaz de relacionar melhor as palavras.\n",
    "\n",
    "Vê se que o potencial desse classificador é muito grande para empresas que recebem \"feedback\" e comentários de muitas pessoas todos os dias, pois o tempo de identificar comentários relevantes seria poupado, além de dar a opção delas darem o \"feedback\" ao consumidor/cliente mais rapidamente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
